# -*- coding: utf-8 -*-
"""p2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YeeJksgJeNhi8Z9pJFsPbs31qOnMxmfn
"""

import pandas as pd
import numpy as np
import json
import os

try:
    from openai import OpenAI
except ImportError:
    !pip install openai
    from openai import OpenAI

class DataQualityGate:
    def __init__(self, source):
        # Universal loader: accepts filepath or DataFrame
        if isinstance(source, str):
            self.df = pd.read_csv(source)
        else:
            self.df = source

    def _compute_metrics(self):
        """The Worker: Calculates raw technical statistics."""
        # 1. Missing Values
        missing = self.df.isnull().sum()
        missing = missing[missing > 0].to_dict()

        # 2. Duplicates
        duplicates = int(self.df.duplicated().sum())

        # 3. Outliers (Heuristic)
        # NOTE: Z-score used as a first-pass heuristic.
        # For production time-series, rolling std dev or IQR is preferred.
        outliers = {}
        numeric_df = self.df.select_dtypes(include=[np.number])
        if not numeric_df.empty:
            z_scores = np.abs((numeric_df - numeric_df.mean()) / numeric_df.std())
            outlier_counts = (z_scores > 3).sum()
            outliers = outlier_counts[outlier_counts > 0].to_dict()

        return {
            "rows": self.df.shape[0],
            "columns": self.df.shape[1],
            "missing_values": missing,
            "duplicate_rows": duplicates,
            "outliers_zscore_3plus": outliers
        }

    def _apply_business_rules(self, stats):
        """The Gatekeeper: Python logic to determine Pass/Fail before AI sees it."""
        rules = []
        status = "PASS"

        # Rule 1: No duplicates allowed
        if stats["duplicate_rows"] > 0:
            status = "FAIL"
            rules.append(f"CRITICAL: Found {stats['duplicate_rows']} duplicate rows.")

        # Rule 2: Max 20% missing data in any column
        for col, count in stats["missing_values"].items():
            if (count / stats["rows"]) > 0.2:
                status = "FAIL"
                rules.append(f"CRITICAL: Column '{col}' missing >20% data.")

        stats["overall_status"] = status
        stats["rule_violations"] = rules
        return stats

    def generate_review_report(self, api_key):
        """The Manager: Sends context-aware prompt to LLM."""
        raw_stats = self._compute_metrics()
        final_stats = self._apply_business_rules(raw_stats)

        client = OpenAI(api_key=api_key)

        # DOMAIN-SPECIFIC PROMPT
        prompt = f"""
        You are a Senior Data Engineer supporting a Power Trading Desk.
        We are preparing a dataset for an XGBoost Demand Forecasting model.

        Review the following automated Data Quality Audit:
        {json.dumps(final_stats, indent=2)}

        Task:
        1. State the 'Overall Status' clearly.
        2. Analyze the 'Outliers': Are these likely grid errors or valid extreme weather events?
        3. Recommend specific Pandas cleaning steps for the missing values.

        Keep it concise, technical, and actionable.
        """

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

# --- USAGE EXAMPLE ---

# 1. Load your data (Reuse the file from Project 1)
df = pd.read_csv('df_train.csv')

# 2. Initialize the Gate
gate = DataQualityGate(df)

# 3. Generate Report
# Replace with your actual key.
# If you don't have one right now, the code below handles the error gracefully.
api_key = "YOUR_OPENAI_API_KEY_HERE"

try:
    print("---  POWER TRADING DATA AUDIT  ---")
    report = gate.generate_review_report(api_key)
    print(report)
except Exception as e:
    print("\n[!] API Key missing or invalid. Printing raw stats instead:")
    print(json.dumps(gate._apply_business_rules(gate._compute_metrics()), indent=2))